{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d396d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Sagemaker Session and Get Execution Role ##\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97bb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload Training Data to s3 Bucket ##\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "data_dir = 'data' \n",
    "prefix = 'rcmdKNN'\n",
    "input_data = sagemaker_session.upload_data(data_dir, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23dff9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "## Instantiate Estimator Object ##\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "estimator = SKLearn(entry_point='train.py',\n",
    "                    framework_version='0.23-1',\n",
    "                    role=role,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "                    py_version='py3',\n",
    "                    source_dir='source',\n",
    "                    image_uri=None,\n",
    "                    hyperparameters = {'n_neighbors':101,\n",
    "                                       'metric':'cosine',\n",
    "                                       'algorithm':'brute'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833901a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-15 15:08:46 Starting - Starting the training job...\n",
      "2021-12-15 15:09:11 Starting - Launching requested ML instancesProfilerReport-1639580925: InProgress\n",
      "......\n",
      "2021-12-15 15:10:11 Starting - Preparing the instances for training.........."
     ]
    }
   ],
   "source": [
    "## Train the estimator ##\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538edaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define new model object pointing to custom inference code ##\n",
    "\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "\n",
    "sklearn_model = SKLearnModel(model_data=estimator.model_data,\n",
    "                             role=role,\n",
    "                             entry_point=\"predict.py\",\n",
    "                             source_dir='source',\n",
    "                             framework_version='0.23-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdfdcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deploy the estimator ##\n",
    "\n",
    "predictor = sklearn_model.deploy(instance_type=\"ml.m4.xlarge\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32adc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in training data and mapping files ##\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "train_data = scipy.sparse.load_npz('./data/artist_user_mtrx.npz')\n",
    "train_data = np.array(train_data.todense())\n",
    "\n",
    "with open('./datasources/artist_to_idx.pkl', 'rb') as f:\n",
    "    artist_to_idx = pickle.load(f)\n",
    "    \n",
    "with open('./datasources/idx_to_artist.pkl', 'rb') as f:\n",
    "    idx_to_artist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define utility functions to process input/output ##\n",
    "\n",
    "def process_input(artists, input_data):\n",
    "    artist_ids = [artist_to_idx[i] for i in artists]\n",
    "    artist_ids = input_data[artist_ids].reshape(1,-1)\n",
    "    return artist_ids\n",
    "\n",
    "def process_output(reponse, n, verbose=True):\n",
    "    artists = [idx_to_artist[i] for i in reponse]\n",
    "    if verbose:\n",
    "        print ('Recommended Artists: {}'.format(artists[1:n+1]))\n",
    "    return artists[1:n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6fb2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate some predictions for select artists ##\n",
    "\n",
    "for artist in ['the beatles', 'eagles', 'genesis', 'nirvana', 'the strokes']:\n",
    "    print ('\\nInput artist: {} \\n'.format(artist))\n",
    "    input_data = process_input([artist], train_data)\n",
    "    response = predictor.predict(input_data)\n",
    "    process_output(response, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02332b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist Hit Rate for 100 Users (10 Recommendations per User): 28%\n"
     ]
    }
   ],
   "source": [
    "## Calculate 'hit rate' ##\n",
    "def rcmnd_from_fav(user, data, num_preds = 100):\n",
    "    play_history = data[:,user]\n",
    "    artist_idx = (-play_history).argsort()[:1]\n",
    "    predictions = predictor.predict(data[artist_idx].reshape(1,-1))\n",
    "    return predictions[1:num_preds+1]\n",
    "\n",
    "def hit_rate(user, data, predictions):\n",
    "    hits = train_data[:, user][predictions]\n",
    "    return hits\n",
    "\n",
    "hits = []\n",
    "num_users = 100\n",
    "preds_per_user = 10\n",
    "\n",
    "for user in np.random.randint(0, train_data.shape[1], size=num_users):\n",
    "    predictions = rcmnd_from_fav(user, train_data)\n",
    "    hits = hit_rate(user, train_data, predictions)\n",
    "    hits+=hits\n",
    "    \n",
    "rate = (np.count_nonzero(hits) / len(hits))\n",
    "\n",
    "print ('Artist Hit Rate for {} Users ({} Recommendations per User): {:.0%}'\\\n",
    "       .format(num_users, preds_per_user, rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
