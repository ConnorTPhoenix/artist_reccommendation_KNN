{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54c9395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=310c1b97dbe2022daf0b31d6fb02cc68f3f35c7f53a10cfbea5138f4851d44d5\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/90/1d/93/c863ee832230df5cfc25ca497b3e88e0ee3ea9e44adc46ac62\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "import wget\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b13dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download and extract user/artist dataset ##\n",
    "\n",
    "filename = 'lastfm-dataset-360K.tar.gz'\n",
    "source_url = 'http://mtg.upf.edu/static/datasets/last.fm/' + filename\n",
    "data_dir = 'datasources/raw/'\n",
    "\n",
    "def getData(source_url, data_dir, filename):\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    ## Download ##\n",
    "    wget.download(source_url, out=data_dir)\n",
    "    \n",
    "    ## Extract ##\n",
    "    file = tarfile.open('./' + data_dir + filename)\n",
    "    file.extractall(data_dir)\n",
    "    file.close()\n",
    "    \n",
    "getData(source_url, data_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074490ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /Users/connorphoenix/ML_Projects/Udacity_MLE__Recommendation/datasources/raw/lastfm-dataset-360K: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "## View contents of destination datadir ##\n",
    "! ls /Users/connorphoenix/ML_Projects/Udacity_MLE__Recommendation/datasources/raw/lastfm-dataset-360K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a94591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plays DF shape: (17535655, 4)\n",
      "Users DF shape: (67044, 5)\n",
      "Joined DF shape: (3336272, 3)\n"
     ]
    }
   ],
   "source": [
    "## Join artist and user files to filter artist plays to users within the United States ##\n",
    "\n",
    "plays_file = 'usersha1-artmbid-artname-plays.tsv'\n",
    "users_file = 'usersha1-profile.tsv'\n",
    "plays_path = './' + data_dir + 'lastfm-dataset-360K/' + plays_file\n",
    "users_path = './' + data_dir + 'lastfm-dataset-360K/' + users_file\n",
    "\n",
    "def createDF(plays_path, users_path):\n",
    "    ''' - Read in and assign column names to artist play and user datasets, \n",
    "        - Inner join artist play and user datasets on USER_ID\n",
    "        - Generate \"Continent\" column '''\n",
    "    \n",
    "    plays_df = pd.read_csv(plays_path, sep='\\t', header=None)\n",
    "    plays_df.columns = ['User_ID', 'Artist_ID', 'Artist', 'Plays']\n",
    "    print ('Plays DF shape: {}'.format(plays_df.shape))\n",
    "    \n",
    "    users_df = pd.read_csv(users_path, sep='\\t', header=None)\n",
    "    users_df.columns = ['User_ID', 'Gender', 'Age', 'Country', 'SignUp_DT']\n",
    "    users_df = users_df[users_df['Country'] == 'United States']\n",
    "    print ('Users DF shape: {}'.format(users_df.shape))\n",
    "    \n",
    "    fin_df = plays_df.merge(users_df, on ='User_ID', how='inner')  \n",
    "    fin_df = fin_df[['User_ID', 'Artist', 'Plays']]\n",
    "    print ('Final DF shape: {}'.format(fin_df.shape))\n",
    "    \n",
    "    processed_dir = 'datasources/processed/'\n",
    "    processed_file = 'user_artist_plays.csv'\n",
    "    if not os.path.exists(processed_dir):\n",
    "        os.makedirs(processed_dir)\n",
    "\n",
    "    fin_df.to_csv('./' + processed_dir + processed_file, index=False)\n",
    "    \n",
    "    del plays_df, users_df\n",
    "    return fin_df\n",
    "\n",
    "df = createDF(plays_path, users_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf8bd417",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean by deleting raw files ##\n",
    "! rm -rf /home/ec2-user/SageMaker/artist_recommendation_KNN/datasources/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ce706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
